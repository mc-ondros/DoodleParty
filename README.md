# DoodleHunter ðŸŽ¨

A high-resolution CNN binary classifier that distinguishes between penis drawings and common shapes from the QuickDraw dataset.

## Overview

**DoodleHunter** uses TensorFlow/Keras to train a convolutional neural network (CNN) for binary classification:
- **Positive class (1)**: Penis drawings from custom NDJSON dataset
- **Negative class (0)**: 21 common shapes from Google's QuickDraw dataset

The model achieves **97.25% accuracy** on 128Ã—128 high-resolution images rendered from vector strokes.

## Project Structure

```
â”œâ”€â”€ app/                          # Flask web application
â”‚   â”œâ”€â”€ app.py                   # Backend API server
â”‚   â”œâ”€â”€ static/                  # CSS, JavaScript
â”‚   â”œâ”€â”€ templates/               # HTML templates
â”‚   â””â”€â”€ requirements.txt         # Web app dependencies
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Raw NDJSON stroke data (21 QuickDraw classes)
â”‚   â””â”€â”€ processed/               # Preprocessed 128Ã—128 numpy arrays
â”‚       â”œâ”€â”€ X_train.npy         # Training images (40,320 samples, 2.5GB)
â”‚       â”œâ”€â”€ X_test.npy          # Test images (10,080 samples, 630MB)
â”‚       â”œâ”€â”€ y_train.npy         # Training labels
â”‚       â”œâ”€â”€ y_test.npy          # Test labels
â”‚       â””â”€â”€ class_mapping.pkl   # Class to index mapping
â”œâ”€â”€ models/
â”‚   â””â”€â”€ quickdraw_model.h5      # Trained CNN model (296MB, 25.8M params)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_processing/        # Data preparation scripts
â”‚   â””â”€â”€ visualization/          # Visualization utilities
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset.py              # Data loading and preprocessing
â”‚   â”œâ”€â”€ train.py                # Model training script
â”‚   â”œâ”€â”€ predict.py              # Inference and evaluation
â”‚   â””â”€â”€ models.py               # Model architecture definitions
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ ML_API_DOCUMENTATION.md # Comprehensive API documentation
â”œâ”€â”€ quickdraw_appendix/         # Custom penis drawing dataset
â””â”€â”€ requirements.txt            # Python dependencies
```

## Setup

### Prerequisites

- Python 3.8+
- pip

### Installation

1. Clone the repository:
```bash
git clone https://github.com/mc-ondros/DoodleHunter.git
cd DoodleHunter
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

## Usage

### 1. Download and Process Data

```bash
# Download QuickDraw NDJSON files (vector strokes, not pre-rendered)
python scripts/data_processing/download_quickdraw_ndjson.py

# Process all data to 128Ã—128 from vector strokes
python scripts/data_processing/process_all_data_128x128.py

# Generate training/test splits (80/20)
python scripts/data_processing/regenerate_training_data.py
```

### 2. Train the Model

```bash
# Train for 50 epochs with batch size 32
python src/train.py

# Model saved to: models/quickdraw_model.h5
# Training takes ~8 hours on CPU (Intel with AVX512)
```

### 3. Run the Web Interface

```bash
cd app
flask run --host=0.0.0.0 --port=5000

# Or use the launcher script:
bash run_interface.sh

# Access at: http://localhost:5000
```

### 4. Make Predictions via API

```bash
# Using curl
curl -X POST http://localhost:5000/api/predict \
  -H "Content-Type: application/json" \
  -d '{"image": "data:image/png;base64,..."}'

# Response:
# {
#   "success": true,
#   "verdict": "PENIS",
#   "confidence": 0.9234,
#   "raw_probability": 0.9234
# }
```

## Model Architecture

```
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)               â”ƒ Output Shape        â”ƒ    Param #   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Conv2D + BatchNorm (Ã—3)    â”‚ (None, 28, 28, 128) â”‚    93,696    â”‚
â”‚ MaxPooling2D + Dropout     â”‚                     â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Flatten                    â”‚ (None, 100352)      â”‚         0    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dense + BatchNorm          â”‚ (None, 256)         â”‚ 25,690,368   â”‚
â”‚ Dropout                    â”‚                     â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dense + BatchNorm          â”‚ (None, 128)         â”‚    32,896    â”‚
â”‚ Dropout                    â”‚                     â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dense (sigmoid)            â”‚ (None, 1)           â”‚       129    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Total params: 25,818,499 (98.49 MB)
Trainable params: 25,817,281
```

**Key Features**:
- Input: 128Ã—128 grayscale images
- Binary classification with sigmoid output
- Per-image normalization prevents brightness shortcuts
- Optimized with Adam, binary crossentropy loss

## Dataset

### Positive Class: Penis Drawings
- **Source**: Custom NDJSON dataset (quickdraw_appendix/)
- **Samples**: 25,209 drawings
- **Format**: Vector strokes rendered to 128Ã—128 bitmaps
- **Stroke Width**: 12px on 256Ã—256 canvas â†’ 6px at 128Ã—128

### Negative Class: QuickDraw Common Shapes
- **Source**: Google QuickDraw dataset NDJSON files
- **Categories** (21 classes, 1,200 samples each):
  - airplane, apple, arm, banana, bird, boomerang
  - cat, circle, cloud, dog, drill, fish, flower
  - house, moon, pencil, square, star, sun, tree, triangle
- **Total**: 25,200 drawings
- **Rendering**: Same pipeline as positive class (consistent 6px strokes)

### Preprocessing Pipeline
1. Render vector strokes at 256Ã—256 with 12px width
2. Downsample to 128Ã—128 using LANCZOS filter (preserves sharpness)
3. Normalize to [0, 1] range
4. **Per-image normalization**: `(x - mean) / std` then rescale to [0, 1]
5. Result: Grey background (~0.45), white strokes (~0.9-1.0)

### Data Split
- **Training**: 40,320 samples (50% positive, 50% negative)
- **Testing**: 10,080 samples (stratified split)
- **Augmentation**: None (model generalizes well without it)

## Performance Metrics

**Test Set Results**:
- **Accuracy**: 97.25% (9,802 / 10,080 correct)
- **Penis Detection**: ~95% probability on true positives
- **Shape Detection**: ~3-7% probability on true negatives
- **Inference Time**: ~70ms per image (CPU), ~4ms per image (batched)

**Model Characteristics**:
- Robust to drawing style variations
- Handles different stroke thicknesses well (5-8px effective width)
- Minimal false positives on common shapes
- No data augmentation needed - generalizes well

## Web Interface

The included Flask web app provides an interactive drawing canvas:

**Features**:
- 512Ã—512 HTML5 canvas for smooth drawing
- Adjustable brush size (5-50px, default 24px)
- Real-time predictions with confidence scores
- Automatic preprocessing matching training pipeline
- ~100ms total response time (drawing â†’ result)

**Technical Details**:
- Canvas: White background, black strokes
- Preprocessing: Inverts colors, resizes to 128Ã—128, applies per-image normalization
- API: RESTful JSON endpoints for predictions and health checks

## Documentation

See [`docs/ML_API_DOCUMENTATION.md`](docs/ML_API_DOCUMENTATION.md) for comprehensive API documentation including:
- Detailed preprocessing pipeline
- Drawing guidelines for optimal results  
- Common issues and solutions
- Python and JavaScript usage examples
- Batch processing and real-time inference

## Troubleshooting

**Model predicts everything as "OTHER_SHAPE"**
- âœ“ Increase brush size (use 24px+ on 512Ã—512 canvas)
- âœ“ Verify strokes are thick enough (>10% bright pixels after preprocessing)

**Low confidence on clear drawings**
- âœ“ Ensure per-image normalization is applied
- âœ“ Check that preprocessed mean â‰ˆ 0.5

**Poor performance on new drawings**
- âœ“ Match training data stroke width (~6px at 128Ã—128)
- âœ“ Use continuous strokes, avoid scattered dots

## Future Improvements

- [ ] Multi-class classification to identify specific shapes
- [ ] GPU optimization for faster inference
- [ ] Model quantization for mobile deployment
- [ ] Additional training data from user submissions
- [ ] A/B testing for threshold optimization

## License

MIT

## References

- QuickDraw Dataset: https://github.com/googlecreativelab/quickdraw-dataset
- TensorFlow: https://www.tensorflow.org/
- Keras: https://keras.io/
